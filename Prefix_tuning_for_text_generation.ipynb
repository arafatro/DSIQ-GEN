{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "d2f21ecd-44d9-4b61-b98b-64e4831ff13e",
      "metadata": {
        "id": "d2f21ecd-44d9-4b61-b98b-64e4831ff13e"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b549fe1-fea3-4e83-8d29-ef3a0c8449b6",
      "metadata": {
        "id": "1b549fe1-fea3-4e83-8d29-ef3a0c8449b6"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from transformers import Trainer, TrainingArguments, DataCollatorForLanguageModeling\n",
        "import torch\n",
        "from peft import LoraConfig, PromptTuningConfig, PromptEncoderConfig, PrefixTuningConfig, TaskType, PeftModel, PromptTuningInit, get_peft_model\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datasets\n",
        "from datasets import load_dataset, load_from_disk, Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eed502aa-d3dc-48f9-a9bc-3aebf10347df",
      "metadata": {
        "id": "eed502aa-d3dc-48f9-a9bc-3aebf10347df"
      },
      "source": [
        "# Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "12bea43b-4546-4f8b-b803-890aae7902eb",
      "metadata": {
        "id": "12bea43b-4546-4f8b-b803-890aae7902eb"
      },
      "outputs": [],
      "source": [
        "model_name = \"NousResearch/Llama-3.2-1B\"\n",
        "NUM_VIRTUAL_TOKENS = 88\n",
        "NUM_EPOCHS = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e2e42d2-037c-462f-aa56-a07b116c335b",
      "metadata": {
        "id": "6e2e42d2-037c-462f-aa56-a07b116c335b"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.padding_side = \"right\"\n",
        "foundational_model = AutoModelForCausalLM.from_pretrained(model_name, trust_remote_code=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "866c1ecd-74bb-48b4-823a-ca098c635084",
      "metadata": {
        "id": "866c1ecd-74bb-48b4-823a-ca098c635084"
      },
      "outputs": [],
      "source": [
        "def tokenizer_function(dataset):\n",
        "    question = []\n",
        "    input_ids = []\n",
        "    attention_mask = []\n",
        "    for elm in dataset[\"question\"]:\n",
        "        question.append(elm)\n",
        "        prompt = \"Example of a data science interview question: \" + elm\n",
        "        #print(prompt)\n",
        "        inputs = tokenizer(prompt)\n",
        "        input_ids.append(inputs[\"input_ids\"])\n",
        "        attention_mask.append(inputs[\"attention_mask\"])\n",
        "    ds = Dataset.from_dict({\"question\": question, \"input_ids\": input_ids, \"attention_mask\": attention_mask})\n",
        "    return ds"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6315a950-83d7-425a-af9f-22b45d3394bf",
      "metadata": {
        "id": "6315a950-83d7-425a-af9f-22b45d3394bf"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "458cbef2-7cde-4255-8601-89b89031a0d9",
      "metadata": {
        "id": "458cbef2-7cde-4255-8601-89b89031a0d9",
        "outputId": "da1cd24f-9fb5-4de4-affc-c401915bd6de"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "      <th>difficulty</th>\n",
              "      <th>topic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What are augmentations? Why do we need them?</td>\n",
              "      <td>Augmentations are an artifical way of expandin...</td>\n",
              "      <td>beginner</td>\n",
              "      <td>neural networks</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What’s the difference between random forest an...</td>\n",
              "      <td>1. Random Forests builds each tree independent...</td>\n",
              "      <td>intermediate</td>\n",
              "      <td>feature selection</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>How large should be N for our bag of words whe...</td>\n",
              "      <td>Answer here</td>\n",
              "      <td>intermediate</td>\n",
              "      <td>text classification</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What is the normal equation?</td>\n",
              "      <td>Normal equations are equations obtained by set...</td>\n",
              "      <td>intermediate</td>\n",
              "      <td>supervised learning</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What if we want to build a model for predictin...</td>\n",
              "      <td>Data is not normal. Specially, real-world data...</td>\n",
              "      <td>intermediate</td>\n",
              "      <td>supervised learning</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            question  \\\n",
              "0       What are augmentations? Why do we need them?   \n",
              "1  What’s the difference between random forest an...   \n",
              "2  How large should be N for our bag of words whe...   \n",
              "3                       What is the normal equation?   \n",
              "4  What if we want to build a model for predictin...   \n",
              "\n",
              "                                              answer    difficulty  \\\n",
              "0  Augmentations are an artifical way of expandin...      beginner   \n",
              "1  1. Random Forests builds each tree independent...  intermediate   \n",
              "2                                        Answer here  intermediate   \n",
              "3  Normal equations are equations obtained by set...  intermediate   \n",
              "4  Data is not normal. Specially, real-world data...  intermediate   \n",
              "\n",
              "                 topic  \n",
              "0      neural networks  \n",
              "1    feature selection  \n",
              "2  text classification  \n",
              "3  supervised learning  \n",
              "4  supervised learning  "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset = load_dataset(\"csv\", data_files=\"dataset_6.csv\")\n",
        "dataset = dataset[\"train\"].train_test_split(test_size=0.1)\n",
        "df = pd.DataFrame(dataset['train'])\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "29d31e71-efa2-4fe0-8574-eee32e5a12d0",
      "metadata": {
        "id": "29d31e71-efa2-4fe0-8574-eee32e5a12d0",
        "outputId": "8f093237-58b3-4f1f-a06c-779666b1fbff"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>input_ids</th>\n",
              "      <th>attention_mask</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What are augmentations? Why do we need them?</td>\n",
              "      <td>[128000, 13617, 315, 264, 828, 8198, 7274, 348...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What’s the difference between random forest an...</td>\n",
              "      <td>[128000, 13617, 315, 264, 828, 8198, 7274, 348...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>How large should be N for our bag of words whe...</td>\n",
              "      <td>[128000, 13617, 315, 264, 828, 8198, 7274, 348...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What is the normal equation?</td>\n",
              "      <td>[128000, 13617, 315, 264, 828, 8198, 7274, 348...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What if we want to build a model for predictin...</td>\n",
              "      <td>[128000, 13617, 315, 264, 828, 8198, 7274, 348...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145</th>\n",
              "      <td>Why do we need to split our data into three pa...</td>\n",
              "      <td>[128000, 13617, 315, 264, 828, 8198, 7274, 348...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>What is precision and recall at k?</td>\n",
              "      <td>[128000, 13617, 315, 264, 828, 8198, 7274, 348...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>What kind of augmentations do you know?</td>\n",
              "      <td>[128000, 13617, 315, 264, 828, 8198, 7274, 348...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>What’s the difference between L2 and L1 regula...</td>\n",
              "      <td>[128000, 13617, 315, 264, 828, 8198, 7274, 348...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>What is K-fold cross-validation?</td>\n",
              "      <td>[128000, 13617, 315, 264, 828, 8198, 7274, 348...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>150 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              question  \\\n",
              "0         What are augmentations? Why do we need them?   \n",
              "1    What’s the difference between random forest an...   \n",
              "2    How large should be N for our bag of words whe...   \n",
              "3                         What is the normal equation?   \n",
              "4    What if we want to build a model for predictin...   \n",
              "..                                                 ...   \n",
              "145  Why do we need to split our data into three pa...   \n",
              "146                 What is precision and recall at k?   \n",
              "147            What kind of augmentations do you know?   \n",
              "148  What’s the difference between L2 and L1 regula...   \n",
              "149                   What is K-fold cross-validation?   \n",
              "\n",
              "                                             input_ids  \\\n",
              "0    [128000, 13617, 315, 264, 828, 8198, 7274, 348...   \n",
              "1    [128000, 13617, 315, 264, 828, 8198, 7274, 348...   \n",
              "2    [128000, 13617, 315, 264, 828, 8198, 7274, 348...   \n",
              "3    [128000, 13617, 315, 264, 828, 8198, 7274, 348...   \n",
              "4    [128000, 13617, 315, 264, 828, 8198, 7274, 348...   \n",
              "..                                                 ...   \n",
              "145  [128000, 13617, 315, 264, 828, 8198, 7274, 348...   \n",
              "146  [128000, 13617, 315, 264, 828, 8198, 7274, 348...   \n",
              "147  [128000, 13617, 315, 264, 828, 8198, 7274, 348...   \n",
              "148  [128000, 13617, 315, 264, 828, 8198, 7274, 348...   \n",
              "149  [128000, 13617, 315, 264, 828, 8198, 7274, 348...   \n",
              "\n",
              "                                        attention_mask  \n",
              "0    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
              "1    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
              "2    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
              "3        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]  \n",
              "4    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
              "..                                                 ...  \n",
              "145  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
              "146  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
              "147  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
              "148  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
              "149   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]  \n",
              "\n",
              "[150 rows x 3 columns]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_sample = tokenizer_function(dataset[\"train\"])\n",
        "df = pd.DataFrame(train_sample)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b15e4102-63d1-4af7-8290-761722eccd0f",
      "metadata": {
        "id": "b15e4102-63d1-4af7-8290-761722eccd0f",
        "outputId": "5ce478bd-f1d2-4238-8090-b298c0ea3ee3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>input_ids</th>\n",
              "      <th>attention_mask</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What is TF-IDF? How is it useful for text clas...</td>\n",
              "      <td>[128000, 13617, 315, 264, 828, 8198, 7274, 348...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What methods for solving linear regression do ...</td>\n",
              "      <td>[128000, 13617, 315, 264, 828, 8198, 7274, 348...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>How do we know how many trees we need in rando...</td>\n",
              "      <td>[128000, 13617, 315, 264, 828, 8198, 7274, 348...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>How would you evaluate your ranking algorithms...</td>\n",
              "      <td>[128000, 13617, 315, 264, 828, 8198, 7274, 348...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What is mean average precision at k?</td>\n",
              "      <td>[128000, 13617, 315, 264, 828, 8198, 7274, 348...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>What is a time series?</td>\n",
              "      <td>[128000, 13617, 315, 264, 828, 8198, 7274, 348...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Which feature selection techniques do you know?</td>\n",
              "      <td>[128000, 13617, 315, 264, 828, 8198, 7274, 348...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>You have a series with a variable “y” and a se...</td>\n",
              "      <td>[128000, 13617, 315, 264, 828, 8198, 7274, 348...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>What is the area under the PR curve? Is it a u...</td>\n",
              "      <td>[128000, 13617, 315, 264, 828, 8198, 7274, 348...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Can we have both L1 and L2 regularization comp...</td>\n",
              "      <td>[128000, 13617, 315, 264, 828, 8198, 7274, 348...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Is feature selection important for linear models?</td>\n",
              "      <td>[128000, 13617, 315, 264, 828, 8198, 7274, 348...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Why do we need activation functions?</td>\n",
              "      <td>[128000, 13617, 315, 264, 828, 8198, 7274, 348...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>How we can use neural nets for computer vision?</td>\n",
              "      <td>[128000, 13617, 315, 264, 828, 8198, 7274, 348...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>What are precision, recall, and F1-score?</td>\n",
              "      <td>[128000, 13617, 315, 264, 828, 8198, 7274, 348...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>What is random forest?</td>\n",
              "      <td>[128000, 13617, 315, 264, 828, 8198, 7274, 348...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Can we use L2 regularization for feature selec...</td>\n",
              "      <td>[128000, 13617, 315, 264, 828, 8198, 7274, 348...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>What’s pooling in CNN? Why do we need it?</td>\n",
              "      <td>[128000, 13617, 315, 264, 828, 8198, 7274, 348...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             question  \\\n",
              "0   What is TF-IDF? How is it useful for text clas...   \n",
              "1   What methods for solving linear regression do ...   \n",
              "2   How do we know how many trees we need in rando...   \n",
              "3   How would you evaluate your ranking algorithms...   \n",
              "4                What is mean average precision at k?   \n",
              "5                              What is a time series?   \n",
              "6     Which feature selection techniques do you know?   \n",
              "7   You have a series with a variable “y” and a se...   \n",
              "8   What is the area under the PR curve? Is it a u...   \n",
              "9   Can we have both L1 and L2 regularization comp...   \n",
              "10  Is feature selection important for linear models?   \n",
              "11               Why do we need activation functions?   \n",
              "12    How we can use neural nets for computer vision?   \n",
              "13          What are precision, recall, and F1-score?   \n",
              "14                             What is random forest?   \n",
              "15  Can we use L2 regularization for feature selec...   \n",
              "16          What’s pooling in CNN? Why do we need it?   \n",
              "\n",
              "                                            input_ids  \\\n",
              "0   [128000, 13617, 315, 264, 828, 8198, 7274, 348...   \n",
              "1   [128000, 13617, 315, 264, 828, 8198, 7274, 348...   \n",
              "2   [128000, 13617, 315, 264, 828, 8198, 7274, 348...   \n",
              "3   [128000, 13617, 315, 264, 828, 8198, 7274, 348...   \n",
              "4   [128000, 13617, 315, 264, 828, 8198, 7274, 348...   \n",
              "5   [128000, 13617, 315, 264, 828, 8198, 7274, 348...   \n",
              "6   [128000, 13617, 315, 264, 828, 8198, 7274, 348...   \n",
              "7   [128000, 13617, 315, 264, 828, 8198, 7274, 348...   \n",
              "8   [128000, 13617, 315, 264, 828, 8198, 7274, 348...   \n",
              "9   [128000, 13617, 315, 264, 828, 8198, 7274, 348...   \n",
              "10  [128000, 13617, 315, 264, 828, 8198, 7274, 348...   \n",
              "11  [128000, 13617, 315, 264, 828, 8198, 7274, 348...   \n",
              "12  [128000, 13617, 315, 264, 828, 8198, 7274, 348...   \n",
              "13  [128000, 13617, 315, 264, 828, 8198, 7274, 348...   \n",
              "14  [128000, 13617, 315, 264, 828, 8198, 7274, 348...   \n",
              "15  [128000, 13617, 315, 264, 828, 8198, 7274, 348...   \n",
              "16  [128000, 13617, 315, 264, 828, 8198, 7274, 348...   \n",
              "\n",
              "                                       attention_mask  \n",
              "0   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
              "1   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
              "2   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
              "3   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
              "4   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
              "5       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]  \n",
              "6   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
              "7   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
              "8   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
              "9   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
              "10  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
              "11   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]  \n",
              "12  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
              "13  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
              "14         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]  \n",
              "15  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
              "16  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  "
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "val_sample = tokenizer_function(dataset[\"test\"])\n",
        "df = pd.DataFrame(val_sample)\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ef396e26-de0d-4533-aa7e-b2dfd13656ed",
      "metadata": {
        "id": "ef396e26-de0d-4533-aa7e-b2dfd13656ed"
      },
      "source": [
        "# Prefix tuning model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9d0a4b3-508f-43aa-b3f6-5339337026f5",
      "metadata": {
        "id": "a9d0a4b3-508f-43aa-b3f6-5339337026f5",
        "outputId": "049cc974-cf70-42f0-c252-2d103ed99403"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trainable params: 1,441,792 || all params: 1,237,256,192 || trainable%: 0.1165\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "generation_config = PrefixTuningConfig(\n",
        "    peft_type=\"PREFIX_TUNING\",\n",
        "    task_type=TaskType.CAUSAL_LM,  # This type indicates the model will generate text.\n",
        "    num_virtual_tokens=NUM_VIRTUAL_TOKENS,  # Number of virtual tokens to be added and trained.\n",
        "    #token_dim=280,\n",
        "    #num_transformer_submodules=1,\n",
        "    #num_attention_heads=12,\n",
        "    #num_layers=12,\n",
        "    #encoder_hidden_size=128,\n",
        "    #base_model_name_or_path = model_name\n",
        ")\n",
        "\n",
        "peft_model = get_peft_model(foundational_model, generation_config)\n",
        "print(peft_model.print_trainable_parameters())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22776da0-363e-4dea-acf0-59c41d1aa367",
      "metadata": {
        "id": "22776da0-363e-4dea-acf0-59c41d1aa367",
        "outputId": "23ec9ac0-adfd-4010-e211-3896757495fd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PeftModelForCausalLM(\n",
              "  (base_model): LlamaForCausalLM(\n",
              "    (model): LlamaModel(\n",
              "      (embed_tokens): Embedding(128256, 2048)\n",
              "      (layers): ModuleList(\n",
              "        (0-15): 16 x LlamaDecoderLayer(\n",
              "          (self_attn): LlamaAttention(\n",
              "            (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
              "            (k_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
              "            (v_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
              "            (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
              "          )\n",
              "          (mlp): LlamaMLP(\n",
              "            (gate_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
              "            (up_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
              "            (down_proj): Linear(in_features=8192, out_features=2048, bias=False)\n",
              "            (act_fn): SiLU()\n",
              "          )\n",
              "          (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
              "          (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
              "        )\n",
              "      )\n",
              "      (norm): LlamaRMSNorm((2048,), eps=1e-05)\n",
              "      (rotary_emb): LlamaRotaryEmbedding()\n",
              "    )\n",
              "    (lm_head): Linear(in_features=2048, out_features=128256, bias=False)\n",
              "  )\n",
              "  (prompt_encoder): ModuleDict(\n",
              "    (default): PrefixEncoder(\n",
              "      (embedding): Embedding(88, 16384)\n",
              "    )\n",
              "  )\n",
              "  (word_embeddings): Embedding(128256, 2048)\n",
              ")"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "peft_model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d5ea4538-0717-459a-88f7-fe0e4319bc78",
      "metadata": {
        "id": "d5ea4538-0717-459a-88f7-fe0e4319bc78"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "32fa6f63-6a1c-462f-810b-e2f2523082c1",
      "metadata": {
        "id": "32fa6f63-6a1c-462f-810b-e2f2523082c1"
      },
      "outputs": [],
      "source": [
        "def create_training_arguments(path, epochs=6):\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir = path,\n",
        "        num_train_epochs = epochs,\n",
        "        per_device_train_batch_size = 4,\n",
        "        per_device_eval_batch_size = 4,\n",
        "        torch_empty_cache_steps = 100,\n",
        "        #optim = optim,\n",
        "        learning_rate = 1e-3,\n",
        "        max_grad_norm = 0.3,\n",
        "        weight_decay = 0.01,\n",
        "        lr_scheduler_type = \"cosine\",\n",
        "        warmup_ratio = 0.03,\n",
        "        #eval_strategy=\"steps\",\n",
        "        #eval_steps=10,\n",
        "        #save_strategy=\"steps\",\n",
        "        eval_strategy=\"epoch\",\n",
        "        save_strategy=\"epoch\",\n",
        "        load_best_model_at_end=True,\n",
        "        save_safetensors = True,\n",
        "        save_only_model = True,\n",
        "    )\n",
        "    return training_args"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e6c7fe2-4dd7-4c0e-b60d-368b997f9fb9",
      "metadata": {
        "id": "0e6c7fe2-4dd7-4c0e-b60d-368b997f9fb9"
      },
      "outputs": [],
      "source": [
        "training_args = create_training_arguments(\"output/prefix\", NUM_EPOCHS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "07705a7d-6860-452c-979b-f3db2072f281",
      "metadata": {
        "id": "07705a7d-6860-452c-979b-f3db2072f281"
      },
      "outputs": [],
      "source": [
        "def create_trainer(model, training_args, train_dataset, val_dataset):\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,  # The args for the training.\n",
        "        train_dataset=train_dataset,\n",
        "        eval_dataset=val_dataset,\n",
        "        data_collator=DataCollatorForLanguageModeling(\n",
        "            tokenizer, mlm=False\n",
        "        ),  # mlm=False indicates not to use masked language modeling\n",
        "    )\n",
        "    return trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c07dbfe7-0ebe-4b32-8845-4a7ac2d6ee1e",
      "metadata": {
        "id": "c07dbfe7-0ebe-4b32-8845-4a7ac2d6ee1e",
        "outputId": "d0362fd1-2f7b-4e6f-ce22-ba07069b0d7b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='380' max='380' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [380/380 00:34, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>4.757418</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>3.960869</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>3.715076</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>No log</td>\n",
              "      <td>3.527806</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>No log</td>\n",
              "      <td>3.427896</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>No log</td>\n",
              "      <td>3.354516</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>No log</td>\n",
              "      <td>3.333267</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>No log</td>\n",
              "      <td>3.306718</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>No log</td>\n",
              "      <td>3.291918</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>No log</td>\n",
              "      <td>3.291041</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=380, training_loss=3.4148382889597038, metrics={'train_runtime': 34.2445, 'train_samples_per_second': 43.803, 'train_steps_per_second': 11.097, 'total_flos': 235108208074752.0, 'train_loss': 3.4148382889597038, 'epoch': 10.0})"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer = create_trainer(peft_model, training_args, train_sample, val_sample)\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5e7da4c6-ebd5-4f6d-b2c7-91191da5049e",
      "metadata": {
        "id": "5e7da4c6-ebd5-4f6d-b2c7-91191da5049e"
      },
      "source": [
        "# Inference, question generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18fdb4bf-87e4-4386-8b2a-e26ad411fc1c",
      "metadata": {
        "id": "18fdb4bf-87e4-4386-8b2a-e26ad411fc1c"
      },
      "outputs": [],
      "source": [
        "def generate_new_question(model, prompt_text = \"Example of a data science interview question: \"):\n",
        "    inputs = tokenizer(prompt_text, return_tensors=\"pt\")\n",
        "    outputs = model.generate(input_ids=inputs[\"input_ids\"].to(\"cuda\"), attention_mask=inputs[\"attention_mask\"].to(\"cuda\"), pad_token_id=tokenizer.pad_token_id, eos_token_id=tokenizer.eos_token_id, min_new_tokens=5, max_new_tokens=50, stop_strings=[\"None\", \"question:\", \"Question:\", \"Answer:\"], tokenizer=tokenizer, repetition_penalty=2.0, early_stopping=True, do_sample=True, num_beams=5, temperature=1.75, top_p=0.5, min_p=0.05)\n",
        "    text_output = tokenizer.batch_decode(outputs.detach().cpu().numpy(), skip_special_tokens=True)[0]\n",
        "    #print(text_output)\n",
        "    text_output = text_output[len(prompt_text):]\n",
        "    text_output = text_output[:text_output.find(\"?\")+1]\n",
        "    if len(text_output) > 3:\n",
        "        if text_output[0] in \"0123456789\" and text_output[1:3] == \". \":\n",
        "          text_output = text_output[3:]\n",
        "        elif text_output[:2] == \"1 \":\n",
        "          text_output = text_output[2:]\n",
        "        elif text_output[0] in \"0123456789\" and text_output[1:3] == \") \":\n",
        "          text_output = text_output[3:]\n",
        "    return text_output.strip()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b6b549d3-2cda-4a50-a706-0acf2ca76c41",
      "metadata": {
        "id": "b6b549d3-2cda-4a50-a706-0acf2ca76c41"
      },
      "source": [
        "# Text generation for evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "47133826-52c5-40dd-a41e-a6fb52e6bbf9",
      "metadata": {
        "id": "47133826-52c5-40dd-a41e-a6fb52e6bbf9"
      },
      "outputs": [],
      "source": [
        "# checkpoints: [38, 76, 114, 152, 190, 228, 266, 304, 342, 380]\n",
        "for num in range(380, 381, 38):\n",
        "    load_path = \"output/prefix/checkpoint-\" + str(num)\n",
        "\n",
        "    model_name = 'NousResearch/Llama-3.2-1B'\n",
        "    base_model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "    model = PeftModel.from_pretrained(base_model, load_path)\n",
        "    model = model.to(\"cuda\")\n",
        "\n",
        "    questions = set()\n",
        "    for i in range(100):\n",
        "        question = generate_new_question(model)\n",
        "        words = question.split()\n",
        "        if len(question) >= 10 and len(words) >= 3:\n",
        "            questions.add(question)\n",
        "\n",
        "    with open('output/evaluation/prefix/checkpoint-' + str(num) + '.txt', 'a') as file:\n",
        "        for question in questions:\n",
        "            file.write(question + '\\n')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}