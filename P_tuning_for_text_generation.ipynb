{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "79633c3e-d17a-4707-a713-2669aed4cb17",
      "metadata": {
        "id": "79633c3e-d17a-4707-a713-2669aed4cb17"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b549fe1-fea3-4e83-8d29-ef3a0c8449b6",
      "metadata": {
        "id": "1b549fe1-fea3-4e83-8d29-ef3a0c8449b6"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from transformers import Trainer, TrainingArguments, DataCollatorForLanguageModeling\n",
        "import torch\n",
        "from peft import LoraConfig, PromptTuningConfig, PromptEncoderConfig, PrefixTuningConfig, TaskType, PeftModel, PromptTuningInit, get_peft_model\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datasets\n",
        "from datasets import load_dataset, load_from_disk, Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "15be28bc-6256-47c2-85d8-12d2467e7be5",
      "metadata": {
        "id": "15be28bc-6256-47c2-85d8-12d2467e7be5"
      },
      "source": [
        "# Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "12bea43b-4546-4f8b-b803-890aae7902eb",
      "metadata": {
        "id": "12bea43b-4546-4f8b-b803-890aae7902eb"
      },
      "outputs": [],
      "source": [
        "model_name = \"NousResearch/Llama-3.2-1B\"\n",
        "NUM_VIRTUAL_TOKENS = 500\n",
        "NUM_EPOCHS = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e2e42d2-037c-462f-aa56-a07b116c335b",
      "metadata": {
        "id": "6e2e42d2-037c-462f-aa56-a07b116c335b"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.padding_side = \"right\"\n",
        "foundational_model = AutoModelForCausalLM.from_pretrained(model_name, trust_remote_code=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "866c1ecd-74bb-48b4-823a-ca098c635084",
      "metadata": {
        "id": "866c1ecd-74bb-48b4-823a-ca098c635084"
      },
      "outputs": [],
      "source": [
        "def tokenizer_function(dataset):\n",
        "    question = []\n",
        "    input_ids = []\n",
        "    attention_mask = []\n",
        "    for elm in dataset[\"question\"]:\n",
        "        question.append(elm)\n",
        "        prompt = \"Example of a data science interview question: \" + elm\n",
        "        inputs = tokenizer(prompt)\n",
        "        input_ids.append(inputs[\"input_ids\"])\n",
        "        attention_mask.append(inputs[\"attention_mask\"])\n",
        "    ds = Dataset.from_dict({\"question\": question, \"input_ids\": input_ids, \"attention_mask\": attention_mask})\n",
        "    return ds"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "df925e29-7e88-4203-8c70-51448b86d5f6",
      "metadata": {
        "id": "df925e29-7e88-4203-8c70-51448b86d5f6"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "458cbef2-7cde-4255-8601-89b89031a0d9",
      "metadata": {
        "id": "458cbef2-7cde-4255-8601-89b89031a0d9",
        "outputId": "49718760-6c06-4692-d292-a1fe235b8866"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "      <th>difficulty</th>\n",
              "      <th>topic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What if we set all the weights of a neural net...</td>\n",
              "      <td>If all the weights of a neural network are set...</td>\n",
              "      <td>intermediate</td>\n",
              "      <td>neural networks</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What is the ROC curve? When to use it?</td>\n",
              "      <td>ROC stands for *Receiver Operating Characteris...</td>\n",
              "      <td>intermediate</td>\n",
              "      <td>classification</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>What is the PR (precision-recall) curve?</td>\n",
              "      <td>A *precision*-*recall curve* (or PR Curve) is ...</td>\n",
              "      <td>intermediate</td>\n",
              "      <td>classification</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Do we want to have a constant learning rate or...</td>\n",
              "      <td>Generally, it is recommended to start learning...</td>\n",
              "      <td>intermediate</td>\n",
              "      <td>neural networks</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>How can we use CNN for text classification?</td>\n",
              "      <td>Answer here</td>\n",
              "      <td>advanced</td>\n",
              "      <td>text classification</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            question  \\\n",
              "0  What if we set all the weights of a neural net...   \n",
              "1             What is the ROC curve? When to use it?   \n",
              "2           What is the PR (precision-recall) curve?   \n",
              "3  Do we want to have a constant learning rate or...   \n",
              "4        How can we use CNN for text classification?   \n",
              "\n",
              "                                              answer    difficulty  \\\n",
              "0  If all the weights of a neural network are set...  intermediate   \n",
              "1  ROC stands for *Receiver Operating Characteris...  intermediate   \n",
              "2  A *precision*-*recall curve* (or PR Curve) is ...  intermediate   \n",
              "3  Generally, it is recommended to start learning...  intermediate   \n",
              "4                                        Answer here      advanced   \n",
              "\n",
              "                 topic  \n",
              "0      neural networks  \n",
              "1       classification  \n",
              "2       classification  \n",
              "3      neural networks  \n",
              "4  text classification  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset = load_dataset(\"csv\", data_files=\"dataset_6.csv\")\n",
        "dataset = dataset[\"train\"].train_test_split(test_size=0.1)\n",
        "df = pd.DataFrame(dataset['train'])\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "29d31e71-efa2-4fe0-8574-eee32e5a12d0",
      "metadata": {
        "id": "29d31e71-efa2-4fe0-8574-eee32e5a12d0",
        "outputId": "6793609c-09d5-4349-dff7-f9d6b54d727c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>input_ids</th>\n",
              "      <th>attention_mask</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What if we set all the weights of a neural net...</td>\n",
              "      <td>[128000, 13617, 315, 264, 828, 8198, 7274, 348...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What is the ROC curve? When to use it?</td>\n",
              "      <td>[128000, 13617, 315, 264, 828, 8198, 7274, 348...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>What is the PR (precision-recall) curve?</td>\n",
              "      <td>[128000, 13617, 315, 264, 828, 8198, 7274, 348...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Do we want to have a constant learning rate or...</td>\n",
              "      <td>[128000, 13617, 315, 264, 828, 8198, 7274, 348...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>How can we use CNN for text classification?</td>\n",
              "      <td>[128000, 13617, 315, 264, 828, 8198, 7274, 348...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145</th>\n",
              "      <td>What’s the effect of L2 regularization on the ...</td>\n",
              "      <td>[128000, 13617, 315, 264, 828, 8198, 7274, 348...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>How do we check if a variable follows the norm...</td>\n",
              "      <td>[128000, 13617, 315, 264, 828, 8198, 7274, 348...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>What is TF-IDF? How is it useful for text clas...</td>\n",
              "      <td>[128000, 13617, 315, 264, 828, 8198, 7274, 348...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>Which regularization techniques do you know?</td>\n",
              "      <td>[128000, 13617, 315, 264, 828, 8198, 7274, 348...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>What are the problems with sigmoid as an activ...</td>\n",
              "      <td>[128000, 13617, 315, 264, 828, 8198, 7274, 348...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>150 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              question  \\\n",
              "0    What if we set all the weights of a neural net...   \n",
              "1               What is the ROC curve? When to use it?   \n",
              "2             What is the PR (precision-recall) curve?   \n",
              "3    Do we want to have a constant learning rate or...   \n",
              "4          How can we use CNN for text classification?   \n",
              "..                                                 ...   \n",
              "145  What’s the effect of L2 regularization on the ...   \n",
              "146  How do we check if a variable follows the norm...   \n",
              "147  What is TF-IDF? How is it useful for text clas...   \n",
              "148       Which regularization techniques do you know?   \n",
              "149  What are the problems with sigmoid as an activ...   \n",
              "\n",
              "                                             input_ids  \\\n",
              "0    [128000, 13617, 315, 264, 828, 8198, 7274, 348...   \n",
              "1    [128000, 13617, 315, 264, 828, 8198, 7274, 348...   \n",
              "2    [128000, 13617, 315, 264, 828, 8198, 7274, 348...   \n",
              "3    [128000, 13617, 315, 264, 828, 8198, 7274, 348...   \n",
              "4    [128000, 13617, 315, 264, 828, 8198, 7274, 348...   \n",
              "..                                                 ...   \n",
              "145  [128000, 13617, 315, 264, 828, 8198, 7274, 348...   \n",
              "146  [128000, 13617, 315, 264, 828, 8198, 7274, 348...   \n",
              "147  [128000, 13617, 315, 264, 828, 8198, 7274, 348...   \n",
              "148  [128000, 13617, 315, 264, 828, 8198, 7274, 348...   \n",
              "149  [128000, 13617, 315, 264, 828, 8198, 7274, 348...   \n",
              "\n",
              "                                        attention_mask  \n",
              "0    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
              "1    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
              "2    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
              "3    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
              "4    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
              "..                                                 ...  \n",
              "145  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
              "146  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
              "147  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
              "148   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]  \n",
              "149  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
              "\n",
              "[150 rows x 3 columns]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_sample = tokenizer_function(dataset[\"train\"])\n",
        "df = pd.DataFrame(train_sample)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b15e4102-63d1-4af7-8290-761722eccd0f",
      "metadata": {
        "id": "b15e4102-63d1-4af7-8290-761722eccd0f",
        "outputId": "4d88aa87-487b-400b-887c-8e1b4cd69ee2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>input_ids</th>\n",
              "      <th>attention_mask</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Is it easy to parallelize training of a random...</td>\n",
              "      <td>[128000, 13617, 315, 264, 828, 8198, 7274, 348...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What is the cold start problem?</td>\n",
              "      <td>[128000, 13617, 315, 264, 828, 8198, 7274, 348...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>When do we need to perform feature normalizati...</td>\n",
              "      <td>[128000, 13617, 315, 264, 828, 8198, 7274, 348...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>How would you evaluate your ranking algorithms...</td>\n",
              "      <td>[128000, 13617, 315, 264, 828, 8198, 7274, 348...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>How do you approach tuning parameters in XGBoo...</td>\n",
              "      <td>[128000, 13617, 315, 264, 828, 8198, 7274, 348...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>What is backpropagation? How does it work? Why...</td>\n",
              "      <td>[128000, 13617, 315, 264, 828, 8198, 7274, 348...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Can we use L1 regularization for feature selec...</td>\n",
              "      <td>[128000, 13617, 315, 264, 828, 8198, 7274, 348...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>What is classification? Which models would you...</td>\n",
              "      <td>[128000, 13617, 315, 264, 828, 8198, 7274, 348...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>What is object detection? Do you know any arch...</td>\n",
              "      <td>[128000, 13617, 315, 264, 828, 8198, 7274, 348...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>If a weight for one variable is higher than fo...</td>\n",
              "      <td>[128000, 13617, 315, 264, 828, 8198, 7274, 348...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>What is SGD — stochastic gradient descent? Wha...</td>\n",
              "      <td>[128000, 13617, 315, 264, 828, 8198, 7274, 348...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>What methods for solving linear regression do ...</td>\n",
              "      <td>[128000, 13617, 315, 264, 828, 8198, 7274, 348...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Why do we need randomization in random forest?</td>\n",
              "      <td>[128000, 13617, 315, 264, 828, 8198, 7274, 348...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>What are word embeddings? Why are they useful?...</td>\n",
              "      <td>[128000, 13617, 315, 264, 828, 8198, 7274, 348...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Do you know how to use gradient boosting trees...</td>\n",
              "      <td>[128000, 13617, 315, 264, 828, 8198, 7274, 348...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>What are the benefits of a single decision tre...</td>\n",
              "      <td>[128000, 13617, 315, 264, 828, 8198, 7274, 348...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>What is a recommender system?</td>\n",
              "      <td>[128000, 13617, 315, 264, 828, 8198, 7274, 348...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             question  \\\n",
              "0   Is it easy to parallelize training of a random...   \n",
              "1                     What is the cold start problem?   \n",
              "2   When do we need to perform feature normalizati...   \n",
              "3   How would you evaluate your ranking algorithms...   \n",
              "4   How do you approach tuning parameters in XGBoo...   \n",
              "5   What is backpropagation? How does it work? Why...   \n",
              "6   Can we use L1 regularization for feature selec...   \n",
              "7   What is classification? Which models would you...   \n",
              "8   What is object detection? Do you know any arch...   \n",
              "9   If a weight for one variable is higher than fo...   \n",
              "10  What is SGD — stochastic gradient descent? Wha...   \n",
              "11  What methods for solving linear regression do ...   \n",
              "12     Why do we need randomization in random forest?   \n",
              "13  What are word embeddings? Why are they useful?...   \n",
              "14  Do you know how to use gradient boosting trees...   \n",
              "15  What are the benefits of a single decision tre...   \n",
              "16                      What is a recommender system?   \n",
              "\n",
              "                                            input_ids  \\\n",
              "0   [128000, 13617, 315, 264, 828, 8198, 7274, 348...   \n",
              "1   [128000, 13617, 315, 264, 828, 8198, 7274, 348...   \n",
              "2   [128000, 13617, 315, 264, 828, 8198, 7274, 348...   \n",
              "3   [128000, 13617, 315, 264, 828, 8198, 7274, 348...   \n",
              "4   [128000, 13617, 315, 264, 828, 8198, 7274, 348...   \n",
              "5   [128000, 13617, 315, 264, 828, 8198, 7274, 348...   \n",
              "6   [128000, 13617, 315, 264, 828, 8198, 7274, 348...   \n",
              "7   [128000, 13617, 315, 264, 828, 8198, 7274, 348...   \n",
              "8   [128000, 13617, 315, 264, 828, 8198, 7274, 348...   \n",
              "9   [128000, 13617, 315, 264, 828, 8198, 7274, 348...   \n",
              "10  [128000, 13617, 315, 264, 828, 8198, 7274, 348...   \n",
              "11  [128000, 13617, 315, 264, 828, 8198, 7274, 348...   \n",
              "12  [128000, 13617, 315, 264, 828, 8198, 7274, 348...   \n",
              "13  [128000, 13617, 315, 264, 828, 8198, 7274, 348...   \n",
              "14  [128000, 13617, 315, 264, 828, 8198, 7274, 348...   \n",
              "15  [128000, 13617, 315, 264, 828, 8198, 7274, 348...   \n",
              "16  [128000, 13617, 315, 264, 828, 8198, 7274, 348...   \n",
              "\n",
              "                                       attention_mask  \n",
              "0   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
              "1    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]  \n",
              "2   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
              "3   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
              "4   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
              "5   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
              "6   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
              "7   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
              "8   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
              "9   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
              "10  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
              "11  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
              "12  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
              "13  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
              "14  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
              "15  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
              "16   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]  "
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "val_sample = tokenizer_function(dataset[\"test\"])\n",
        "df = pd.DataFrame(val_sample)\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cf63f00b-49ba-438c-b6a4-c24487d659bd",
      "metadata": {
        "id": "cf63f00b-49ba-438c-b6a4-c24487d659bd"
      },
      "source": [
        "# P-tuning model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9d0a4b3-508f-43aa-b3f6-5339337026f5",
      "metadata": {
        "id": "a9d0a4b3-508f-43aa-b3f6-5339337026f5",
        "outputId": "5b66c442-1c74-4d03-b751-8c392cf17e4c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trainable params: 1,024,000 || all params: 1,236,838,400 || trainable%: 0.0828\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "generation_config = PromptTuningConfig(\n",
        "    peft_type=\"P_TUNING\",\n",
        "    task_type=TaskType.CAUSAL_LM,  # This type indicates the model will generate text.\n",
        "    prompt_tuning_init=PromptTuningInit.RANDOM,  # The added virtual tokens are initializad with random numbers\n",
        "    num_virtual_tokens=NUM_VIRTUAL_TOKENS,  # Number of virtual tokens to be added and trained.\n",
        "    tokenizer_name_or_path=model_name,  # The pre-trained model.\n",
        ")\n",
        "\n",
        "peft_model = get_peft_model(foundational_model, generation_config)\n",
        "print(peft_model.print_trainable_parameters())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe64a812-a5f0-4c64-a1b2-09be6445c821",
      "metadata": {
        "id": "fe64a812-a5f0-4c64-a1b2-09be6445c821",
        "outputId": "02a635a3-a18d-49e5-e22b-ccc959784229"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PeftModelForCausalLM(\n",
              "  (base_model): LlamaForCausalLM(\n",
              "    (model): LlamaModel(\n",
              "      (embed_tokens): Embedding(128256, 2048)\n",
              "      (layers): ModuleList(\n",
              "        (0-15): 16 x LlamaDecoderLayer(\n",
              "          (self_attn): LlamaAttention(\n",
              "            (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
              "            (k_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
              "            (v_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
              "            (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
              "          )\n",
              "          (mlp): LlamaMLP(\n",
              "            (gate_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
              "            (up_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
              "            (down_proj): Linear(in_features=8192, out_features=2048, bias=False)\n",
              "            (act_fn): SiLU()\n",
              "          )\n",
              "          (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
              "          (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
              "        )\n",
              "      )\n",
              "      (norm): LlamaRMSNorm((2048,), eps=1e-05)\n",
              "      (rotary_emb): LlamaRotaryEmbedding()\n",
              "    )\n",
              "    (lm_head): Linear(in_features=2048, out_features=128256, bias=False)\n",
              "  )\n",
              "  (prompt_encoder): ModuleDict(\n",
              "    (default): PromptEmbedding(\n",
              "      (embedding): Embedding(500, 2048)\n",
              "    )\n",
              "  )\n",
              "  (word_embeddings): Embedding(128256, 2048)\n",
              ")"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "debd34da-0560-4544-a25d-6912478b221b",
      "metadata": {
        "id": "debd34da-0560-4544-a25d-6912478b221b"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "32fa6f63-6a1c-462f-810b-e2f2523082c1",
      "metadata": {
        "id": "32fa6f63-6a1c-462f-810b-e2f2523082c1"
      },
      "outputs": [],
      "source": [
        "def create_training_arguments(path, epochs=6):\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir = path,\n",
        "        num_train_epochs = epochs,\n",
        "        per_device_train_batch_size = 4,\n",
        "        per_device_eval_batch_size = 4,\n",
        "        torch_empty_cache_steps = 100,\n",
        "        #optim = optim,\n",
        "        learning_rate = 1e-3,\n",
        "        max_grad_norm = 0.3,\n",
        "        weight_decay = 0.01,\n",
        "        lr_scheduler_type = \"cosine\",\n",
        "        warmup_ratio = 0.03,\n",
        "        #eval_strategy=\"steps\",\n",
        "        #eval_steps=10,\n",
        "        #save_strategy=\"steps\",\n",
        "        eval_strategy=\"epoch\",\n",
        "        save_strategy=\"epoch\",\n",
        "        load_best_model_at_end=True,\n",
        "        save_safetensors = True,\n",
        "        save_only_model = True,\n",
        "    )\n",
        "    return training_args"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e6c7fe2-4dd7-4c0e-b60d-368b997f9fb9",
      "metadata": {
        "id": "0e6c7fe2-4dd7-4c0e-b60d-368b997f9fb9"
      },
      "outputs": [],
      "source": [
        "training_args = create_training_arguments(\"output/p-tuning\", NUM_EPOCHS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "07705a7d-6860-452c-979b-f3db2072f281",
      "metadata": {
        "id": "07705a7d-6860-452c-979b-f3db2072f281"
      },
      "outputs": [],
      "source": [
        "def create_trainer(model, training_args, train_dataset, val_dataset):\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,  # The args for the training.\n",
        "        train_dataset=train_dataset,\n",
        "        eval_dataset=val_dataset,\n",
        "        data_collator=DataCollatorForLanguageModeling(\n",
        "            tokenizer, mlm=False\n",
        "        ),  # mlm=False indicates not to use masked language modeling\n",
        "    )\n",
        "    return trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c07dbfe7-0ebe-4b32-8845-4a7ac2d6ee1e",
      "metadata": {
        "id": "c07dbfe7-0ebe-4b32-8845-4a7ac2d6ee1e",
        "outputId": "8c2fe044-7596-4851-d724-0367d4bfb671"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='380' max='380' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [380/380 07:43, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>4.377367</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>3.361925</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>3.073158</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.891921</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.764492</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.683021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.634903</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.606918</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.597763</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.596462</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=380, training_loss=2.91003128854852, metrics={'train_runtime': 465.1755, 'train_samples_per_second': 3.225, 'train_steps_per_second': 0.817, 'total_flos': 235096530321408.0, 'train_loss': 2.91003128854852, 'epoch': 10.0})"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer = create_trainer(peft_model, training_args, train_sample, val_sample)\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b463da9-64a5-40e3-8847-12ff57348198",
      "metadata": {
        "id": "9b463da9-64a5-40e3-8847-12ff57348198"
      },
      "source": [
        "# Inference, question generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18fdb4bf-87e4-4386-8b2a-e26ad411fc1c",
      "metadata": {
        "id": "18fdb4bf-87e4-4386-8b2a-e26ad411fc1c"
      },
      "outputs": [],
      "source": [
        "def generate_new_question(model, prompt_text = \"Example of a data science interview question: \"):\n",
        "    inputs = tokenizer(prompt_text, return_tensors=\"pt\")\n",
        "    outputs = model.generate(input_ids=inputs[\"input_ids\"].to(\"cuda\"), attention_mask=inputs[\"attention_mask\"].to(\"cuda\"), pad_token_id=tokenizer.pad_token_id, eos_token_id=tokenizer.eos_token_id, min_new_tokens=5, max_new_tokens=50, stop_strings=[\"None\", \"question:\", \"Question:\", \"Answer:\"], tokenizer=tokenizer, repetition_penalty=2.0, early_stopping=True, do_sample=True, num_beams=3, temperature=1.5, top_p=0.75, min_p=0.1)\n",
        "    text_output = tokenizer.batch_decode(outputs.detach().cpu().numpy(), skip_special_tokens=True)[0]\n",
        "    text_output = text_output[len(prompt_text):]\n",
        "    text_output = text_output[:text_output.find(\"?\")+1]\n",
        "    if len(text_output) > 3:\n",
        "        if text_output[0] in \"0123456789\" and text_output[1:3] == \". \":\n",
        "          text_output = text_output[3:]\n",
        "        elif text_output[:2] == \"1 \":\n",
        "          text_output = text_output[2:]\n",
        "        elif text_output[0] in \"0123456789\" and text_output[1:3] == \") \":\n",
        "          text_output = text_output[3:]\n",
        "    return text_output.strip()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7906ee66-b36c-4891-9b0a-1adf5f2ebd74",
      "metadata": {
        "id": "7906ee66-b36c-4891-9b0a-1adf5f2ebd74"
      },
      "source": [
        "# Text generation for evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "91507c32-ae4a-451b-8a97-41f82ce256d2",
      "metadata": {
        "id": "91507c32-ae4a-451b-8a97-41f82ce256d2"
      },
      "outputs": [],
      "source": [
        "# checkpoints: [38, 76, 114, 152, 190, 228, 266, 304, 342, 380]\n",
        "for num in range(380, 381, 38):\n",
        "    load_path = \"output/p-tuning/checkpoint-\" + str(num)\n",
        "\n",
        "    model_name = 'NousResearch/Llama-3.2-1B'\n",
        "    base_model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "    model = PeftModel.from_pretrained(base_model, load_path)\n",
        "    model = model.to(\"cuda\")\n",
        "\n",
        "    questions = set()\n",
        "    for i in range(100):\n",
        "        question = generate_new_question(model)\n",
        "        words = question.split()\n",
        "        if len(question) >= 10 and len(words) >= 3:\n",
        "            questions.add(question)\n",
        "\n",
        "    with open('output/evaluation/p-tuning/checkpoint-' + str(num) + '.txt', 'a') as file:\n",
        "        for question in questions:\n",
        "            file.write(question + '\\n')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}